{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='sparse_categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('../dataset/cifar/train/*.png')[:1000]\n",
    "test_paths = glob('../dataset/cifar/test/*.png')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 2.3237 - accuracy: 0.1054 - val_loss: 2.3006 - val_accuracy: 0.1401\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 2.2857 - accuracy: 0.1312 - val_loss: 2.2914 - val_accuracy: 0.1401\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 2.2771 - accuracy: 0.1230 - val_loss: 2.2395 - val_accuracy: 0.1583\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 2.2354 - accuracy: 0.1631 - val_loss: 2.2251 - val_accuracy: 0.1431\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 2.1731 - accuracy: 0.1890 - val_loss: 2.0923 - val_accuracy: 0.2087\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 2.1595 - accuracy: 0.1829 - val_loss: 2.0610 - val_accuracy: 0.2702\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 2.0411 - accuracy: 0.2572 - val_loss: 2.0432 - val_accuracy: 0.2369\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 1.9983 - accuracy: 0.2438 - val_loss: 1.9843 - val_accuracy: 0.2550\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 2.0288 - accuracy: 0.2460 - val_loss: 1.9991 - val_accuracy: 0.2752\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 1.9567 - accuracy: 0.2701 - val_loss: 1.9529 - val_accuracy: 0.2671\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 1.8696 - accuracy: 0.2996 - val_loss: 1.8709 - val_accuracy: 0.3438\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 1.8813 - accuracy: 0.2800 - val_loss: 1.9505 - val_accuracy: 0.3105\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 1.9056 - accuracy: 0.2843 - val_loss: 1.8967 - val_accuracy: 0.2994\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 1.8307 - accuracy: 0.3157 - val_loss: 1.8687 - val_accuracy: 0.3014\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 1.8138 - accuracy: 0.3202 - val_loss: 1.7970 - val_accuracy: 0.3407\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 1.7335 - accuracy: 0.3605 - val_loss: 1.7856 - val_accuracy: 0.3276\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 1.7424 - accuracy: 0.3518 - val_loss: 1.7893 - val_accuracy: 0.3558\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 1.7373 - accuracy: 0.3481 - val_loss: 1.7545 - val_accuracy: 0.3609\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 1.6569 - accuracy: 0.3771 - val_loss: 1.7267 - val_accuracy: 0.3710\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 1.6898 - accuracy: 0.3998 - val_loss: 1.8214 - val_accuracy: 0.3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x277436ee4f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지를 Load 직접 load해서 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = train_paths[0]\n",
    "test_image, test_label = load_image_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = test_image[tf.newaxis, ...]\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00186033, 0.00111492, 0.08962503, 0.10541584, 0.1498315 ,\n",
       "        0.13173772, 0.4373092 , 0.08186253, 0.00072246, 0.00052034]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator에서 데이터를 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_image)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00986753, 0.00304143, 0.08633912, 0.27564576, 0.1151012 ,\n",
       "       0.20519562, 0.08399658, 0.20291476, 0.00921955, 0.00867846],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_dataset.take(2))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 996us/step - loss: 1.7172 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(test_dataset))\n",
    "evals =  model.evaluate(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0])\n",
    "plt.title(class_names[np.argmax(label[0])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
       "       'horse', 'ship', 'truck'], dtype='<U10')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
