{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# This code is based on\n",
    "# https://github.com/hunkim/DeepRL-Agents\n",
    "\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# From http://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "# default value = 0  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   \n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# 예전 소스 실행을 위한 설정\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상적인 경우를 확인하기 위해서는 is_slippery를 False로 하고 확인해야 함\n",
    "# 즉 지시하는 방향으로 정상적으로 움직임\n",
    "# is_slippery를 True일 경우 정상적으로 움직이지 않음\n",
    "\n",
    "# is_slippery가 False이면 않미끄러짐, True이면 미끄러짐\n",
    "register(\n",
    "    id='FrozenLake-v3',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': True}\n",
    ")\n",
    "\n",
    "env = gym.make('FrozenLake-v3')\n",
    "\n",
    "# Input and output size based on the Env\n",
    "input_size = env.observation_space.n;\n",
    "output_size = env.action_space.n;\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set Q-learning parameters\n",
    "dis = .99\n",
    "num_episodes = 2000\n",
    "\n",
    "\n",
    "def one_hot(x):\n",
    "    return np.identity(16)[x:x+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 71.2758059501648 seconds ---\n",
      "Success rate: 0.524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# These lines establish the feed-forward part of the network used to choose actions\n",
    "# 1 x 16\n",
    "X = tf.placeholder(shape=[1, input_size], dtype=tf.float32)              # state input\n",
    "\n",
    "# 16 x 4\n",
    "W = tf.Variable(tf.random_uniform([input_size, output_size], 0, 0.01))   # weight\n",
    "\n",
    "# Out Q prediction  vector(1 x 16) x matrix(16 x 4) = vector(1 x 4)\n",
    "# Qpred는 수식\n",
    "Qpred = tf.matmul(X, W)\n",
    "\n",
    "# 1 x 4\n",
    "Y = tf.placeholder(shape=[1, output_size], dtype=tf.float32)    # Y label\n",
    "\n",
    "# loss는 수식\n",
    "loss = tf.reduce_sum(tf.square(Y-Qpred))\n",
    "\n",
    "# train은 수식\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        # s는 맵상에서 현재 위치\n",
    "        s = env.reset()\n",
    "        \n",
    "        #현재 위치 확인        \n",
    "        #env.render()\n",
    "        \n",
    "        e = 1. / ((i / 50) + 10)\n",
    "        rAll = 0\n",
    "        done = False\n",
    "        local_loss = []\n",
    "\n",
    "        # The Q-Table learning algorithm\n",
    "        while not done:\n",
    "            # Choose an action by greedly (with a chance of random action)\n",
    "            # from the Q-network \n",
    "            # Qs는 vector(1 x 4)\n",
    "            Qs = sess.run(Qpred, feed_dict={X: one_hot(s)})\n",
    "            \n",
    "            #print('s => ', s)\n",
    "            #print('one_hot(s) => ', one_hot(s))\n",
    "            #print('Qs => ', Qs)\n",
    "            \n",
    "            if np.random.rand(1) < e:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(Qs)\n",
    "\n",
    "            # 최적의 경로를 찾기 위해서 np.argmax(Qs) 사용\n",
    "            #a = np.argmax(Qs)\n",
    "            #print('a => ', a)    \n",
    "            \n",
    "            # Get new state and reward from environment\n",
    "            s1, reward, done, _ = env.step(a)\n",
    "            \n",
    "            #현재 위치 확인\n",
    "            #env.render()\n",
    "\n",
    "            if done:\n",
    "                # Update Q, and no Qs+1, since it's a termial state\n",
    "                Qs[0, a] = reward\n",
    "            else:\n",
    "                # Obtain the Q_s` values by feeding the new state through our network\n",
    "                Qs1 = sess.run(Qpred, feed_dict={X: one_hot(s1)})\n",
    "                \n",
    "                # Update Q, Qs는 정답(label)\n",
    "                Qs[0, a] = reward + dis*np.max(Qs1)\n",
    "\n",
    "            #print('----------------------------------- ')    \n",
    "            # Train our network using target (Y) and predicted Q (Qpred) values\n",
    "            sess.run(train, feed_dict={X: one_hot(s), Y: Qs})\n",
    "\n",
    "            rAll += reward\n",
    "            s = s1\n",
    "        rList.append(rAll)\n",
    "        #print('------------------------------------------------------------------ ')    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Success rate: \" + str(sum(rList) / num_episodes))\n",
    "#plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "plt.bar(range(len(rList)), rList, color='b', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
