{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환신경망 구현 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "NUM_WORDS = 10000\n",
    "MODEL = 1 # 1: RNN, 2:LSTM, 3:GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # 길이가 10000인 one-hot vector를 길이가 16인 feature vector로 변경함\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
    "        \n",
    "        # 32 : RNN의 갯수\n",
    "        if MODEL == 1:\n",
    "            self.rnn = tf.keras.layers.SimpleRNN(32)\n",
    "        elif MODEL == 2:\n",
    "            self.rnn = tf.keras.layers.LSTM(32)\n",
    "        else:\n",
    "            self.rnn = tf.keras.layers.GRU(32)\n",
    "        self.dense = tf.keras.layers.Dense(2, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=None, mask=None):\n",
    "        x = self.emb(x)\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습, 테스트 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement training loop\n",
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "# Implement algorithm test\n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images, training=False)\n",
    "\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])]\n",
      "[1 0]\n",
      "(25000, 32)\n",
      "[[  30 5535   18   51   36   28  224   92   25  104    4  226   65   16\n",
      "    38 1334   88   12   16  283    5   16 4472  113  103   32   15   16\n",
      "  5345   19  178   32]\n",
      " [   9    6  371   78   22  625   64 1382    9    8  168  145   23    4\n",
      "  1690   15   16    4 1355    5   28    6   52  154  462   33   89   78\n",
      "   285   16  145   95]]\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
    "\n",
    "print(x_train[0:2])\n",
    "print(y_train[0:2])\n",
    "\n",
    "# 입력 문장의 길이가 각각 달라서 32로 조정하고\n",
    "# 32보다 길면 뒤쪽부터 32개를 넣고,\n",
    "# 32보다 작으면 앞쪽부터 padding을 0으로 채워줌\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                       value=0,\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=32)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                      value=0,\n",
    "                                                      padding='pre',\n",
    "                                                      maxlen=32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train[0:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 환경 정의\n",
    "### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = MyModel()\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define performance metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL : RNN\n",
      "Epoch 1, Loss: 0.5839154124259949, Accuracy: 66.09600067138672, Test Loss: 0.4963189661502838, Test Accuracy: 75.9679946899414\n",
      "14.715745687484741 seconds elapsed.\n",
      "Epoch 2, Loss: 0.3629997670650482, Accuracy: 84.2040023803711, Test Loss: 0.49189624190330505, Test Accuracy: 77.2959976196289\n",
      "10.089024305343628 seconds elapsed.\n",
      "Epoch 3, Loss: 0.20407110452651978, Accuracy: 92.3239974975586, Test Loss: 0.6146169304847717, Test Accuracy: 75.91600036621094\n",
      "10.112027406692505 seconds elapsed.\n",
      "Epoch 4, Loss: 0.08782748132944107, Accuracy: 96.98799896240234, Test Loss: 0.8317991495132446, Test Accuracy: 73.02400207519531\n",
      "9.963084697723389 seconds elapsed.\n",
      "Epoch 5, Loss: 0.03520545735955238, Accuracy: 98.93599700927734, Test Loss: 1.0458087921142578, Test Accuracy: 73.68800354003906\n",
      "9.964804649353027 seconds elapsed.\n",
      "Epoch 6, Loss: 0.01623946987092495, Accuracy: 99.50799560546875, Test Loss: 1.2195740938186646, Test Accuracy: 75.1240005493164\n",
      "9.938246250152588 seconds elapsed.\n",
      "Epoch 7, Loss: 0.01602185145020485, Accuracy: 99.40799713134766, Test Loss: 1.3405277729034424, Test Accuracy: 74.20800018310547\n",
      "10.015993595123291 seconds elapsed.\n",
      "Epoch 8, Loss: 0.01562565378844738, Accuracy: 99.46399688720703, Test Loss: 1.4171561002731323, Test Accuracy: 73.14800262451172\n",
      "10.08991527557373 seconds elapsed.\n",
      "Epoch 9, Loss: 0.012837201356887817, Accuracy: 99.58799743652344, Test Loss: 1.5521159172058105, Test Accuracy: 71.07599639892578\n",
      "10.225794315338135 seconds elapsed.\n",
      "Epoch 10, Loss: 0.011340850032866001, Accuracy: 99.62799835205078, Test Loss: 1.5869649648666382, Test Accuracy: 73.36800384521484\n",
      "10.11221194267273 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "if MODEL == 1:\n",
    "    print('MODEL : RNN')\n",
    "elif MODEL == 2:\n",
    "    print('MODEL : LSTM')\n",
    "else:\n",
    "    print('MODEL : GRU')\n",
    "\n",
    "# 시간측정 필요. 노트북의 경우 SimpleRNN 방식일 경우 1 epoch당 10초 정도 소요됨\n",
    "# 시간측정 필요. 노트북의 경우 LSTM 방식일 경우 1 epoch당 18초 정도 소요됨\n",
    "# 시간측정 필요. 노트북의 경우 GRU 방식일 경우 1 epoch당 15초 정도 소요됨\n",
    "t = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "    for test_seqs, test_labels in test_ds:\n",
    "        test_step(model, test_seqs, test_labels, loss_object, test_loss, test_accuracy)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    ct = time.time()\n",
    "    print('{} seconds elapsed.'.format(ct - t))\n",
    "    t = ct    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
